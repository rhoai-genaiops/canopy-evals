prompts:
  - file://prompts.txt
providers:
  - id: https
    config:
      url: 'https://granite-lab-llm-hosting.apps.prod.rhoai.rh-aiservices-bu.com/v1/completions' #'http://llama32-predictor.genaiops-playground.svc.cluster.local:8080/v1/completions'
      method: 'POST'
      headers:
        'Content-Type': 'application/json'
        # 'Authorization': 'Bearer 2d09b2beb0710af17fa2fcb8ac76232c'
      body:
        prompt: '{{prompt}}'
      transformResponse: 'json.choices[0].text'
defaultTest:
  assert:
    - type: llm-rubric
      value: does not describe self as an AI, model, or chatbot
      provider:
        id: https
        config:
          url: 'https://granite-lab-llm-hosting.apps.prod.rhoai.rh-aiservices-bu.com/v1/chat/completions' #'http://llama32-predictor.genaiops-playground.svc.cluster.local:8080/v1/completions'
          method: 'POST'
          headers:
            'Content-Type': 'application/json'
            # 'Authorization': 'Bearer 2d09b2beb0710af17fa2fcb8ac76232c'
          body:
            messages:
              - role: system
                content:
                  type: text
                  text: "{{rubricPrompt.0.content}}"
              - role: user
                content:
                  type: text
                  text: "{{rubricPrompt.1.content}}"
          transformResponse: 'json.choices[0].message.content.text'
      options:
        rubricPrompt:
          - role: system
            content: >
              Grade the output by the following specifications, keeping track of the points scored:

              Did the output mention {{x}}? +1 point  
              Did the output describe {{y}}? +1 point  
              Did the output ask to clarify {{z}}? +1 point

              Calculate the score but always pass the test. Output your response in the following JSON format:  
              {pass: true, score: number, reason: string}
          - role: user
            content: "Output: {{ output }}"
    - type: latency
      threshold: 2000
tests:
  - vars:
      text: "Llama 3.2 is a state-of-the-art language model that excels in various natural language processing tasks, including summarization, translation, and question answering."
      # previous_messages:
      # - role: system
      #   content: "You are a summarization expert."
  - vars:
      text: "The Llama 3.2 model has shown remarkable performance in generating coherent and contextually relevant summaries across diverse datasets, making it a valuable tool for summarization tasks."
    # assert:
    # - type: similar
    #   value: Llama 3.2 excels in generating coherent and contextually relevant summaries.
    #   threshold: 0.6